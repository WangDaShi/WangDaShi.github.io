---

layout: posts
title: 大数据技术入门指南

---

### 本文目的

本文旨在为理解“大数据”一词在软件开发领域指代的一系列的技术、框架、工具提供一个思考框架。以防止读者在初次学习“大数据”相关知识的时候陷入具体的技术细节而丧失了对“大数据”技术的整体把握。同时，在了解了大数据技术的整体图景之后读者也可以更有效的学习具体的技术。

### 本文不涉及的内容

一个词语在不同的情景下使用时，往往指代的是相互联系但又不同的东西。对于“大数据”一词，在商业分析领域使用的时候是指一种从大量数据里通过机器学习的方式分析出有商业价值的规律出来的过程；在公共讨论中则更多的是在说一种大企业对用户数据的使用和用户隐私保护。其中“机器学习”一词又与“人工智能”和“神经网络”等概念关联紧密。但以上都不是本文涉及的内容。

### 跳出技术思维理解技术的演进过程

在开始实际内容之前，首先应该剔除单纯的从技术的角度去看待技术的演进过程的想法。否则经常陷入技术思维的死角里。应该意识到技术的进步实际上是应**商业需求**而发展的。企业追求利润，企业意识到存在新的商业模式的可能性，企业推动技术研发，创新产生，技术进步，商业模式成立，获取利润。

用这个思路思考，可以认为大数据的发展过程可以简单描述为：

1. 4G技术和智能手机使得互联网用户的数据和产生的数据产生了几何级的增长。
2. 对大规模数据的分析变得有利可图。
3. 最先面临数据增长的大公司（谷歌等）开始根据自己的业务需求研发新的技术，在这个过程中可能还会使用科研界（大学）已经研究多年的相关理论成果（分布式理论）。
4. 第一批尝试的公司成功之后，其它企业开始模仿。这个阶段一些开源软件被研发出来（apache基金会的Hadoop）
5. 业内大量的普通企业开始逐渐使用，并完成商业模式转变。

以上过程的完整实现大概要10年左右。

### 没有大数据之前的软件开发范式

无论是哪个领域、哪个语言，软件终究是要在计算机上运行的。最简单的抽象：从开发者的角度可以认为一台计算机由CPU、内存、硬盘和网络通讯四部分组成。数据存储在硬盘里，当需要处理的时候从硬盘中读取的内存里，然后由CPU做计算，同时通过网络与互联网进行通讯。无论是什么类型的软件（网站、数据库、游戏服务）无外乎以上的过程。

在这样的模式下当数据量增长之后的解决办法很简单：

1. 把一台计算机上相互无关的功能分解，分别安装在多台计算机上。比如：一家公司同时有网站和聊天工具两个产品，就可以分开部署在两台计算机上。这样平均每台计算机的资源消耗就不会过多。
2. 增大计算机的配置。算力不足就加CPU的核数，内存不够就加内存条，硬盘不够就加更多的硬盘，网络不够就扩带宽。

但这样还是会遇到对应的问题：

1. 不是所有的业务都可以拆分，比如一个网站的两个模块可能都用到了用户功能。

2. 边际效益递减。成本方面：每增加一个CPU的核数，需要的单核成本就会增加，最终会到达一个不能承担的程度。技术方面：由于技术发展的限制，就算没有预算的限制，计算能力也不是可以无限的增长（想象一个有1000核的CPU或者频率达到1000GHZ的CPU）。

软件开发作为一个工程技术，其特点在于权衡技术、成本、盈利等等因素，做出**足够**可用的产品。所以以上模式虽然有问题，但是在数据量没有发生超级增长之前，并不是一个无法解决的问题。事实上永远也不可能出现一个没有任何短处的技术，大数据技术也一样。

### 大数据技术对上面问题的解决方式

数据量几何级增长之后，上面的问题变成无法忍受了（谷歌一天要处理的数据量以亿记）。于是软件开发人员开始思考：

> 是否可以设计这样一个系统，这个系统里面有多台计算机（大于1台，最多上千台），每台计算机的配置不需要很高（所以便宜），使用的配件质量也不需要很好（可能经常会坏），然后通过设计一个**算法**可以调度每一天计算机，让它们一起配合，从而可以完成只有单台配置超级高的计算机才能实现的功能。

这样的系统一般就可以被称为**分布式系统**。

这个系统的关键在于保证所有的计算机相互配合的算法。而且这个算法必须保证即使系统中**一定比例**（这个比例是动态的）的计算机坏了也不会影响系统整体的运行。如果设计出了这样的一个系统，那么上一节提到的问题岂不是就迎刃而解了？如果是数据存储（硬盘、内存）出现瓶颈，那么就把数据拆分后分散存储到每一台计算机上。如果是算力瓶颈，那么就把计算过程拆分到每一台计算机上去计算，然后再整合到一起。如果是数据库瓶颈，那么就把前面说的两种类型整合到一起来实现。

在这个思路之下，谷歌在06年前后发表了三篇论文，相当于公布了他们对这个思路是实现方式。每篇论文对应上述一种模式（GFS、map-reduce、big-table）。谷歌的这个动作相当于提供了对这个问题的一个“标准答案”。于是apache基金会在这三篇论文进行重新实现，于是诞生了hadoop。再然后有了其它的技术：redis、kafka、flink等等。

这里应当注意Hadoop不是一个单一的软件，而是多个软件的统称。这多个软件之间配合可以解决企业在大数据方面的绝大部分问题。所以换句话说，也可以说Hadoop是一套解决方案。

### 大数据技术的核心问题

虽然大数据的技术非常多，但是都是源于上一节所说的思路。所以可以用以下几个核心问题来把握：

1. 分布式系统中的各个计算机（节点）之间如何通讯。可靠通讯如何保证？

2. 分布式系统中如何容错。即如何保证一部分节点失效之后系统整体依然正常？一般解决方式是把数据赋值多份存储到不同的节点上，这样就引出了另一个问题：多个节点上同一份数据如何保证一致，即如果两个节点上同一份数据因为硬件故障不一样的，怎么办？

3. 如何保证可扩展性。即如何保证系统中节点的线性增加不会导致系统整体性能的非线性增长？（否则成本会被推高）

无论什么样的大数据技术都是在用特定的方式来解决上面的问题。

### CAP理论

暂未补充，可自行搜索

### 学习建议

虽然上面介绍了大数据的抽象解释，但是人是无法通过学习抽象的理论来学会东西的，而是要在具体的技术的学习过程中去掌握。因此建议从GFS或者HDFS入手，并在学习的过程当中时刻思考该技术是应什么样的商业场景而产生的？上述核心问题该技术是如何解决的？在掌握的第一项大数据相关技术之后，建议开始粗略的了解其它的大数据技术，并思考上面提到的问题。至此应该就可以达到对“大数据”一词背后的技术有一个整体性的把握。
